# -*- coding: utf-8 -*-
"""predModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1N4U0DEW_0_NDQBNJ3opKh5Y-Vd-sohWD
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

url = 'Link Dataset'

# Baca file Excel dari URL
data = pd.read_excel(url)

# Tampilkan data
print(data)

df = pd.DataFrame(data)

print(df['Negara'].value_counts())

"""## Try Modelling 1"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Conv1D, MaxPooling1D, Flatten, BatchNormalization

# Load dataset and filter for "jepang"
df_jepang = df[df["Negara"] == "United States"]
data_olah = df_jepang[["Tahun", "Harga Pertons"]]

#prices = df_jepang["Harga (per-ton)"].to_numpy()

# Scale data
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data_olah[["Harga Pertons"]])

# Split data into train and test sets
train_size = int(len(scaled_data) * 0.8)
train, test = scaled_data[0:train_size], scaled_data[train_size:]

train_size

# Create sequences for LSTM
seq_length = 6
def create_sequences(data_olah, seq_length):
    sequences = []
    for i in range(len(data_olah) - seq_length):
        sequence = data_olah[i:i + seq_length]
        sequences.append(sequence)
    return np.array(sequences)


train_sequences = create_sequences(train, seq_length)
test_sequences = create_sequences(test, seq_length)

# Prepare data for CNN
#train_sequences = np.expand_dims(train_sequences, axis = 1)
#test_sequences = np.expand_dims(test_sequences, axis = 1)

# Prepare data for training and testing
train_sequences = np.array(train_sequences)
test_sequences = np.array(test_sequences)

test_sequences.shape

# Build CNN-LSTM model
model = Sequential()
model.add(Conv1D(filters=128, kernel_size=3, activation="relu", input_shape=(seq_length, 1)))
model.add(MaxPooling1D(pool_size=2))
model.add(LSTM(128, return_sequences=True))
model.add(LSTM(64))
model.add(Dense(1))
model.compile(loss="mae", optimizer="adam", metrics = ["mse"])

class myCallback(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs={}):
    if(logs.get('mse')<0.02):
      print("\nReached 0.04 mse so cancelling training!")
      self.model.stop_training = True
callbacks = myCallback()

# Train the model
model.fit(train_sequences, train[seq_length:], epochs=100, batch_size=32, validation_data=(train_sequences, train[seq_length:]))

# Train the model
predicted_prices = []
year_to_predict = [2023, 2024, 2025, 2026, 2027]
num_future_years = 4  # Adjust this parameter

# Update the prediction logic to iterate over multiple years
for i in range(num_future_years):
    future_sequence = scaled_data[-seq_length:]
    future_sequence = np.expand_dims(future_sequence, axis=0)
    future_sequence = np.expand_dims(future_sequence, axis=2)

    predicted_price = model.predict(future_sequence)[0][0]
    predicted_price = scaler.inverse_transform(np.array([[predicted_price]]))[0][0]
    predicted_prices.append(predicted_price)

    # Update the future sequence for the next year
    scaled_data = np.append(scaled_data, [predicted_price])
    scaled_data = scaled_data[1:]

predicted_prices

#predicted_prices

# Combine actual and predicted prices
actual_prices = data_olah["Harga Pertons"].values[train_size:]
all_prices = np.concatenate((actual_prices, predicted_prices))

#predicted_price = scaler.inverse_transform(np.array([[predicted_price]]))[0][0]

tahun_grafik = data_olah["Tahun"].to_numpy()
harga_grafik = data_olah["Harga Pertons"].to_numpy()

#predicted_prices[0]

#data_olah[["Harga (per-ton)"]]
# Plot actual and predicted prices
plt.plot(tahun_grafik, harga_grafik, label="Actual Price")
#plt.plot(range(2022, 2022 + 2), predicted_price)
for i in range(num_future_years):
      plt.axvline(x=year_to_predict[i], color="red", linestyle="--", label=f"Predicted Price ({year_to_predict[i]})")
      plt.scatter(year_to_predict[i], predicted_prices[i], color="red", marker="o")


# Add labels and title
plt.xlabel("Year")
plt.ylabel("Harga Pertons")
plt.title("Export Price Tea over Years")

# Add legend
plt.legend()

# Display the plot
plt.show()

# Predict price for next year
#year_to_predict = [2023, 2024, 2025, 2026]   # Adjust this year
# Create a list to store the predicted prices
#predicted_prices = []

# Iterate over the years to predict
#for year in year_to_predict:
#    # Get the future sequence
#    future_sequence = scaled_data[(-(year + 1)) * seq_length:]
#    future_sequence = np.expand_dims(future_sequence, axis=0)

    # Predict the price
#    predicted_price = model.predict(future_sequence)[0, 0]

    # Scale the predicted price back to original range
#    predicted_price = np.array([[predicted_price]])

#    predicted_price = scaler.inverse_transform(predicted_price)[0, 0]



    # Add the predicted price to the list#
#    predicted_prices.append(predicted_price)

"""##Saved Model"""

model.save('Chocolate(United States).h5')
